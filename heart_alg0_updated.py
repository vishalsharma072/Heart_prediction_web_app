# -*- coding: utf-8 -*-
"""Heart_alg0_updated.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10AuemmFTeoJll6LpKr7ag2kQLKQuKwdX
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import itertools
import seaborn as sns
import warnings
from scipy.stats import kendalltau
warnings.filterwarnings("ignore")

heart = pd.read_csv('/content/heart_updated.csv.xls')
heart.columns

heart.head()

print("Heart data set dimensions : {}".format(heart.shape))

heart.isnull().sum()

heart.isna().sum()

from scipy.stats import skew

for col in heart:
    print(col)
    print(skew(heart[col]))

    plt.figure()
    sns.distplot(heart[col])
    plt.show()

skew = heart.skew()
print(skew)

plt. ax = plt.subplots(figsize=(12,12))
sns.heatmap(heart.corr(),annot=True, annot_kws={'size':10})
plt.show()

from scipy.stats import skew

heart["creatinine_phosphokinase"] = np.cbrt(heart["creatinine_phosphokinase"])
heart["serum_creatinine"] = np.cbrt(heart["serum_creatinine"])
#heart["serum_sodium"] = np.cbrt(heart["serum_sodium"])

from scipy.stats import skew

for col in heart:
    print(col)
    print(skew(heart[col]))

    plt.figure()
    sns.distplot(heart[col])
    plt.show()

skew = heart.skew()
print(skew)

plt. ax = plt.subplots(figsize=(12,12))
sns.heatmap(heart.corr(),annot=True, annot_kws={'size':10})
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import kendalltau

#heart = pd.read_csv('heart1234.csv')

feature_names = ['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes', 'ejection_fraction',
                    'high_blood_pressure', 'platelets', 'serum_creatinine', 'serum_sodium',
                    'sex', 'smoking', 'DEATH_EVENT']

# Calculate Kendall's tau for each feature with the target variable
kendall_correlations = {}
for col in feature_names:
    tau, _ = kendalltau(heart[col], heart['DEATH_EVENT'])
    kendall_correlations[col] = abs(tau)

# Convert the dictionary to a DataFrame for easier plotting
kendall_heart = pd.DataFrame.from_dict(kendall_correlations, orient='index', columns=['Kendall_Tau'])

# Sort the DataFrame based on Kendall's tau values
kendall_heart_sorted = kendall_heart.sort_values(by='Kendall_Tau', ascending=False)

kendall_heart

kendall_heart_sorted

plt.figure(figsize=(10, 6))
sns.barplot(x=kendall_heart_sorted['Kendall_Tau'], y=kendall_heart_sorted.index, palette='viridis')
plt.title("Kendall's Rank Correlation Coefficients with DEATH_EVENT")
plt.xlabel("Kendall's Tau")
plt.ylabel("Features")
plt.show()

#Scattered Graph
fig = plt.figure(figsize = (8,8))
ax = fig.gca()
sns.scatterplot(x= "age", y= "ejection_fraction" , hue="DEATH_EVENT",data=heart)
plt.title(" age vs ejection_fraction",fontsize =10)
plt.show()

from sklearn.model_selection import train_test_split

train, test = train_test_split(heart, test_size=0.30)

print(train.shape)
print(test.shape)

print(heart.shape)

#feature_names = ['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',
       #'ejection_fraction', 'high_blood_pressure', 'platelets',
       #'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time',
       #'DEATH_EVENT']
feature_names = ['serum_creatinine', 'ejection_fraction', 'age' ]

X = heart[feature_names]
y = heart.DEATH_EVENT

from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
#from sklearn.ensemble import GradientBoostingClassifier
#from sklearn.tree import DecisionTreeClassifier

from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn import preprocessing

models = []


models.append(('RF', RandomForestClassifier()))
#models.append(('LR', LogisticRegression()))
#models.append(('GNB', GaussianNB()))
#models.append(('SVC', SVC()))
#models.append(('KNN', KNeighborsClassifier()))

#models.append(('DT', DecisionTreeClassifier()))
#models.append(('GB', GradientBoostingClassifier()))

from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report, confusion_matrix

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = heart.DEATH_EVENT, random_state=0)

from sklearn.ensemble import RandomForestClassifier
model=RandomForestClassifier()

model.fit(X_train, y_train)
y_predict=model.predict(X_test)


from sklearn.metrics import classification_report, confusion_matrix

print(classification_report(y_test, y_predict))
print(confusion_matrix(y_test, y_predict))

MLA = [RandomForestClassifier()]

MLA_columns = []
MLA_compare = pd.DataFrame(columns = MLA_columns)


row_index = 0
for alg in MLA:


    predicted = alg.fit(X_train, y_train).predict(X_test)
    fp, tp, th = roc_curve(y_test, predicted)
    MLA_name = alg.__class__.__name__
    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name
    MLA_compare.loc[row_index, 'MLA Train Accuracy'] = round(alg.score(X_train, y_train), 4)
    MLA_compare.loc[row_index, 'MLA Test Accuracy'] = round(alg.score(X_test, y_test), 4)
    MLA_compare.loc[row_index, 'MLA Precission'] = precision_score(y_test, predicted)
    MLA_compare.loc[row_index, 'MLA Recall'] = recall_score(y_test, predicted)
    MLA_compare.loc[row_index, 'MLA AUC'] = auc(fp, tp)

    row_index+=1

MLA_compare.sort_values(by = ['MLA Test Accuracy'], ascending = False, inplace = True)
MLA_compare

names = []
scores = []

for name, model in models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    scores.append(accuracy_score(y_test, y_pred))
    names.append(name)

    tr_split = pd.DataFrame({'Name': names, 'Score': scores})

    print(tr_split)

names = []
scores = []

axis = sns.barplot(x = 'Name', y = 'Score', data = tr_split)
axis.set(xlabel='Classifier', ylabel='Accuracy')

for p in axis.patches:
    height = p.get_height()
    axis.text(p.get_x() + p.get_width()/2, height + 0.005, '{:1.4f}'.format(height), ha="center")

plt.show()

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

names = []
scores = []

for name, model in models:

    kfold = KFold(n_splits=10, shuffle=True, random_state=10)
    score = cross_val_score(model, X, y, cv=kfold, scoring='accuracy').mean()

    names.append(name)
    #kf_cross_val = pd.DataFrame({'Name': names, 'Score': scores})
    scores.append(score)
    kf_cross_val = pd.DataFrame({'Name': names, 'Score': scores})
    print(kf_cross_val)

axis = sns.barplot(x = 'Name', y = 'Score', data = kf_cross_val)
axis.set(xlabel='Classifier', ylabel='Accuracy')

for p in axis.patches:
    height = p.get_height()
    axis.text(p.get_x() + p.get_width()/2, height + 0.005, '{:1.4f}'.format(height), ha="center")

plt.show()

input_data = (1.3,25,65)

input_data_as_numpy_array= np.asarray(input_data)

input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0]== 0):
  print('The Person does not have a Heart Disease')
else:
  print('The Person has Heart Disease')

import pickle

filename = 'trained_model.sav'
pickle.dump(model, open(filename, 'wb'))

#loading the saved model
loaded_model = pickle.load(open('trained_model.sav', 'rb'))

input_data = (1.3,25,65)

input_data_as_numpy_array= np.asarray(input_data)

input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = loaded_model.predict(input_data_reshaped)
print(prediction)

if (prediction[0]== 0):
  print('The Person does not have a Heart Disease')
else:
  print('The Person has Heart Disease')

